{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nafilahhans/ML/blob/main/repo3_06_headline_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHHt5ru2M0Zd"
      },
      "source": [
        "## Reading in the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVRM3-6KM0Zf",
        "outputId": "3276b448-fd69-4443-9407-f984d9b48e30"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9335"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "nyt_dir = 'data/nyt_dataset/articles/'\n",
        "\n",
        "all_headlines = []\n",
        "for filename in os.listdir(nyt_dir):\n",
        "    if 'Articles' in filename:\n",
        "        # Read in all the data from the CSV file\n",
        "        headlines_df = pd.read_csv(nyt_dir + filename)\n",
        "        # Add all of the headlines to our list\n",
        "        all_headlines.extend(list(headlines_df.headline.values))\n",
        "len(all_headlines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyaZ9N3wM0Zi"
      },
      "source": [
        "Let's take a look at our first few headlines:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emLpEzRpM0Zj",
        "outputId": "f8114dfa-b639-4c72-f5b2-db4ea2715f2c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['My Beijing: The Sacred City',\n",
              " '6 Million Riders a Day, 1930s Technology',\n",
              " 'Seeking a Cross-Border Conference',\n",
              " 'Questions for: ‘Despite the “Yuck Factor,” Leeches Are Big in Russian Medicine’',\n",
              " 'Who Is a ‘Criminal’?',\n",
              " 'An Antidote to Europe’s Populism',\n",
              " 'The Cost of a Speech',\n",
              " 'Degradation of the Language',\n",
              " 'On the Power of Being Awful',\n",
              " 'Trump Garbles Pitch on a Revised Health Bill',\n",
              " 'What’s Going On in This Picture? | May 1, 2017',\n",
              " 'Unknown',\n",
              " 'When Patients Hit a Medical Wall',\n",
              " 'Unknown',\n",
              " 'For Pregnant Women, Getting Serious About Whooping Cough',\n",
              " 'Unknown',\n",
              " 'New York City Transit Reporter in Wonderland: Riding the London Tube',\n",
              " 'How to Cut an Avocado Without Cutting Yourself',\n",
              " 'In Fictional Suicide, Health Experts Say They See a Real Cause for Alarm',\n",
              " 'Claims of Liberal Media Bias Hit ESPN, Too']"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_headlines[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ptry8IPgM0Zj"
      },
      "source": [
        "## Cleaning the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3vj8PKXM0Zk",
        "outputId": "3e6d6335-a433-41a7-f48f-1698dfcae3e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8603"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Remove all headlines with the value of \"Unknown\"\n",
        "all_headlines = [h for h in all_headlines if h != \"Unknown\"]\n",
        "len(all_headlines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhlTbf1-M0Zl",
        "outputId": "c2a1a20a-61a9-4ce9-bf11-029982a94c8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['My Beijing: The Sacred City',\n",
              " '6 Million Riders a Day, 1930s Technology',\n",
              " 'Seeking a Cross-Border Conference',\n",
              " 'Questions for: ‘Despite the “Yuck Factor,” Leeches Are Big in Russian Medicine’',\n",
              " 'Who Is a ‘Criminal’?',\n",
              " 'An Antidote to Europe’s Populism',\n",
              " 'The Cost of a Speech',\n",
              " 'Degradation of the Language',\n",
              " 'On the Power of Being Awful',\n",
              " 'Trump Garbles Pitch on a Revised Health Bill',\n",
              " 'What’s Going On in This Picture? | May 1, 2017',\n",
              " 'When Patients Hit a Medical Wall',\n",
              " 'For Pregnant Women, Getting Serious About Whooping Cough',\n",
              " 'New York City Transit Reporter in Wonderland: Riding the London Tube',\n",
              " 'How to Cut an Avocado Without Cutting Yourself',\n",
              " 'In Fictional Suicide, Health Experts Say They See a Real Cause for Alarm',\n",
              " 'Claims of Liberal Media Bias Hit ESPN, Too',\n",
              " 'Is the dream in Australia crumbling?',\n",
              " 'Police in Texas Change Account in Officer’s Fatal Shooting of 15-Year-Old',\n",
              " 'Most Adults Favor Sex Ed. Most Students Don’t Get It.']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_headlines[:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLsGmKw0M0Zm"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FAzZSQeM0Zm",
        "outputId": "0e7907e7-9220-47d8-a4c6-3711ed83403e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total words:  11753\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Tokenize the words in our headlines\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(all_headlines)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "print('Total words: ', total_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aBgQWv8ZM0Zr",
        "outputId": "26fa484e-2784-4fb7-93b8-a99c2a1fba58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'a': 2, 'plan': 82, 'man': 139, 'panama': 2732, 'canal': 7047}\n"
          ]
        }
      ],
      "source": [
        "# Print a subset of the word_index dictionary created by Tokenizer\n",
        "subset_dict = {key: value for key, value in tokenizer.word_index.items() \\\n",
        "               if key in ['a','man','a','plan','a','canal','panama']}\n",
        "print(subset_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kjmic8wTM0Zs",
        "outputId": "ca14790f-502e-4b7b-cc31-07e37a8e446e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[2], [139], [2], [82], [2], [7047], [2732]]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.texts_to_sequences(['a','man','a','plan','a','canal','panama'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHnT80_BM0Zs"
      },
      "source": [
        "## Creating Sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x7as-4R4M0Zt",
        "outputId": "b7ae044e-f4df-4fc9-f09b-3168925cfa59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['my beijing', 'my beijing the', 'my beijing the sacred', 'my beijing the sacred city', '6 million']\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[[52, 1616],\n",
              " [52, 1616, 1],\n",
              " [52, 1616, 1, 1992],\n",
              " [52, 1616, 1, 1992, 125],\n",
              " [126, 346]]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert data to sequence of tokens\n",
        "input_sequences = []\n",
        "for line in all_headlines:\n",
        "    # Convert our headline into a sequence of tokens\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\n",
        "    # Create a series of sequences for each headline\n",
        "    for i in range(1, len(token_list)):\n",
        "        partial_sequence = token_list[:i+1]\n",
        "        input_sequences.append(partial_sequence)\n",
        "\n",
        "print(tokenizer.sequences_to_texts(input_sequences[:5]))\n",
        "input_sequences[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rI_2ZBbSM0Zu"
      },
      "source": [
        "## Padding Sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b15hn2k5M0Zv",
        "outputId": "79a11804-1626-4d9d-e392-63ee945d807e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,   52, 1616], dtype=int32)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "# Determine max sequence length\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "\n",
        "# Pad all sequences with zeros at the beginning to make them all max length\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "input_sequences[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8Lgp1FrM0Zw"
      },
      "source": [
        "## Creating Predictors and Target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIe4342EM0Zx"
      },
      "source": [
        "We also want to split up our sequences into predictors and a target. The last word of the sequence will be our target, and the first words of the sequence will be our predictors. As an example, take a look at the full headline: \"nvidia releases ampere graphics cards\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-u9nmkXOM0Zx"
      },
      "source": [
        "<table>\n",
        "<tr><td>PREDICTORS </td> <td>           TARGET </td></tr>\n",
        "<tr><td>nvidia                   </td> <td>  releases </td></tr>\n",
        "<tr><td>nvidia releases               </td> <td>  ampere </td></tr>\n",
        "<tr><td>nvidia releases ampere      </td> <td>  graphics</td></tr>\n",
        "<tr><td>nvidia releases ampere graphics </td> <td>  cards</td></tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2Rg3pX9M0Zy",
        "outputId": "d50e229d-64c0-4eb7-cb6b-ace2d0f018fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1616,    1, 1992,  125,  346], dtype=int32)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Predictors are every word except the last\n",
        "predictors = input_sequences[:,:-1]\n",
        "# Labels are the last word\n",
        "labels = input_sequences[:,-1]\n",
        "labels[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "670QpFDcM0Zz"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import utils\n",
        "\n",
        "labels = utils.to_categorical(labels, num_classes=total_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIweArT_M0aF"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Input is max sequence length - 1, as we've removed the last word for the label\n",
        "input_len = max_sequence_len - 1\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# Add input embedding layer\n",
        "model.add(Embedding(total_words, 10, input_length=input_len))\n",
        "\n",
        "# Add LSTM layer with 100 units\n",
        "model.add(LSTM(100))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "# Add output layer\n",
        "model.add(Dense(total_words, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlh_V5MJM0aF",
        "outputId": "aadd6ef3-4de3-4a97-96dc-5ba457b0b815"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 27, 10)            117530    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 100)               44400     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 11753)             1187053   \n",
            "=================================================================\n",
            "Total params: 1,348,983\n",
            "Trainable params: 1,348,983\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYuMhLKFM0aG"
      },
      "source": [
        "## Compiling the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_xAd2OmM0aH"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXPBSkdhM0aH"
      },
      "source": [
        "## Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "fQ2_sFoIM0aJ",
        "outputId": "e808683b-8802-43ec-ef78-277f4a7c375a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1666/1666 [==============================] - 7s 5ms/step - loss: 7.8844\n",
            "Epoch 2/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 7.4662\n",
            "Epoch 3/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 7.2597\n",
            "Epoch 4/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 7.0413\n",
            "Epoch 5/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 6.8059\n",
            "Epoch 6/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 6.5669\n",
            "Epoch 7/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 6.3289\n",
            "Epoch 8/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 6.0923\n",
            "Epoch 9/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 5.8652\n",
            "Epoch 10/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 5.6438\n",
            "Epoch 11/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 5.4327\n",
            "Epoch 12/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 5.2319\n",
            "Epoch 13/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 5.0396\n",
            "Epoch 14/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 4.8587\n",
            "Epoch 15/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 4.6898\n",
            "Epoch 16/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 4.5241\n",
            "Epoch 17/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 4.3712\n",
            "Epoch 18/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 4.2282\n",
            "Epoch 19/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 4.0919\n",
            "Epoch 20/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 3.9650\n",
            "Epoch 21/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 3.8485\n",
            "Epoch 22/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 3.7336\n",
            "Epoch 23/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 3.6284\n",
            "Epoch 24/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 3.5313\n",
            "Epoch 25/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 3.4410\n",
            "Epoch 26/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 3.3510\n",
            "Epoch 27/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 3.2669\n",
            "Epoch 28/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 3.1915\n",
            "Epoch 29/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 3.1173\n",
            "Epoch 30/30\n",
            "1666/1666 [==============================] - 7s 4ms/step - loss: 3.0534\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdd03cbf898>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(predictors, labels, epochs=30, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fx7ghQINM0aL"
      },
      "source": [
        "## Making Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpSGf9-kM0aM"
      },
      "outputs": [],
      "source": [
        "def predict_next_token(seed_text):\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "    prediction = model.predict_classes(token_list, verbose=0)\n",
        "    return prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YReWnSViM0aN",
        "outputId": "4451e5ac-5ab2-47f9-9902-b519a75aaaff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-16-bd91571ab9e2>:4: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([7010])"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prediction = predict_next_token(\"today in new york\")\n",
        "prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePZEpGl9M0aO",
        "outputId": "73a920ef-2005-48a4-f09d-72a7c5812214"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['subway’s']"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.sequences_to_texts([prediction])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7b7Yj1fM0aP"
      },
      "source": [
        "## Generate New Headlines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTp6f6tKM0aP"
      },
      "outputs": [],
      "source": [
        "def generate_headline(seed_text, next_words=1):\n",
        "    for _ in range(next_words):\n",
        "        # Predict next token\n",
        "        prediction = predict_next_token(seed_text)\n",
        "        # Convert token to word\n",
        "        next_word = tokenizer.sequences_to_texts([prediction])[0]\n",
        "        # Add next word to the headline. This headline will be used in the next pass of the loop.\n",
        "        seed_text += \" \" + next_word\n",
        "    # Return headline as title-case\n",
        "    return seed_text.title()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7H_pPGqM0aQ",
        "outputId": "82613a11-9b87-44d9-cb83-b62b8bee4958"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Washington Dc Is A New Ground To Win\n",
            "Today In New York Subway’S Service And Straphangers Fuming\n",
            "The School District Has The President States Should Do\n",
            "Crime Has Become A Blow On A Second\n"
          ]
        }
      ],
      "source": [
        "seed_texts = [\n",
        "    'washington dc is',\n",
        "    'today in new york',\n",
        "    'the school district has',\n",
        "    'crime has become']\n",
        "for seed in seed_texts:\n",
        "    print(generate_headline(seed, next_words=5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdzCfO2DM0aT",
        "outputId": "5acd9ab7-ab6e-464f-d90b-382ca81340c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import IPython\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}